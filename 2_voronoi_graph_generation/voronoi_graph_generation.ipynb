{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")) + '/lib/')\n",
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "from lib.blob_extraction import img_preprocess, blob_detect, get_nodes_pos\n",
    "from lib.graph_generate import Delaunay_graph_generate\n",
    "from lib.voronoi_generate import TransformVoronoi_331"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Voronoi Graph Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voronoi_graph_datatset_generate(raw_data_dir, train_data_dir, test_data_dir, tip_num = 331):\n",
    "    \n",
    "    ####  1. Presetting  ####\n",
    "\n",
    "    os.makedirs(train_data_dir, exist_ok=True)  ## make dir for saving train/val data\n",
    "    os.makedirs(test_data_dir, exist_ok=True)  ## make dir for saving test data \n",
    "\n",
    "    raw_data_label = pd.read_csv(os.path.join(os.path.abspath(os.path.join(raw_data_dir, \"..\")), 'targets.csv'), header=0, usecols=['image_name','pose_2', 'pose_6'])  ## read label.csv file\n",
    "    data_label = np.array([raw_data_label['image_name'].values,\n",
    "                       raw_data_label['pose_2'].values,\n",
    "                       raw_data_label['pose_6'].values])\n",
    "\n",
    "    data_label = data_label.T  ## images index with labels (pose2--Y & pose6--Theta_roll)\n",
    "    count = 1  ## record total generated graph number\n",
    "    data_list = []  ## list for saving the graph data\n",
    "    pin_extract_fail = []  ## list for saving the image index which fails of pin extraction \n",
    "    voronoi_fail = []  ## list for saving the image index which fails of voronoi generation \n",
    "    start = time.time()\n",
    "\n",
    "\n",
    "    ####  2. Generating  ####\n",
    "\n",
    "    for i in range(len(data_label)):\n",
    "\n",
    "        image_name = data_label[i][0]\n",
    "\n",
    "        image_dir = raw_data_dir + '/' + image_name\n",
    "\n",
    "        img = cv2.imread(image_dir)  ## get raw image\n",
    "    \n",
    "        ## !!! tune the parameters by yourself, refer to the setup process in the last step !!!\n",
    "        processed = img_preprocess(img, \n",
    "                                   erosion = False,\n",
    "                                   kernel_size = 1,\n",
    "                                   resize_x = 300, \n",
    "                                   resize_y = 300,\n",
    "                                   binary_threshold = 100, \n",
    "                                   circle_x_bias = -1, \n",
    "                                   circle_y_bias = -2, \n",
    "                                   circle_radius_bias = -14)\n",
    "        \n",
    "        ## !!! tune the parameters by yourself, refer to the setup process in the last step !!!\n",
    "        keypoints = blob_detect(processed, minArea = 10, blobColor = 255, \n",
    "                                minCircularity = 0.01, minConvexity = 0.01, \n",
    "                                minInertiaRatio = 0.01, thresholdStep = 5,\n",
    "                                minDistBetweenBlobs = 3.0, minRepeatability = 3)\n",
    " \n",
    "        nodes_pos = get_nodes_pos(keypoints)  ## extracted nodes position\n",
    "\n",
    "        if nodes_pos.shape[0] == tip_num:  ## check nodes size\n",
    "\n",
    "            Axx_canon, Cxx_canon, Cyy_canon, XY_canon = TransformVoronoi_331(borderScale=1.1).transform(nodes_pos)  ## voronoi construction\n",
    "\n",
    "            if len(Axx_canon) == tip_num:  ## check voronoi area size\n",
    "\n",
    "                label = [data_label[i][1],\n",
    "                        data_label[i][2]]  ## pose2--Y & pose6--Theta_roll\n",
    "\n",
    "                nodes_edges = Delaunay_graph_generate(nodes_pos)  ## Delaunay edge construction\n",
    "\n",
    "                edge = torch.tensor(np.array(nodes_edges).T, dtype=torch.long)  ## convert graph edge to tensor\n",
    "\n",
    "                pair = np.asarray([XY_canon[:,0], XY_canon[:,1], Axx_canon[:]]).T  ## graph feature pair, (nodes x, nodes y, voronoi cell area)\n",
    "\n",
    "                x = torch.tensor(pair, dtype=torch.float)  ## convert graph node feature to tensor\n",
    "\n",
    "                d = Data(x=x, edge_index=edge.contiguous(), t=torch.tensor(label))  ## load nodes, edges and labels into Data format\n",
    "\n",
    "                data_list.append(d) ## update graph data list\n",
    "\n",
    "                count = count + 1  ## update total generated graph number\n",
    "\n",
    "                print(\"\\rRaw Image Data loaded \" + str(i+1), end=\"  \")\n",
    "\n",
    "            else:\n",
    "\n",
    "                voronoi_fail.append(i)  ## update list for saving the image index which fails of pin extraction \n",
    "\n",
    "                print(\"\\rRaw Image Data loaded \" + str(i+1), end=\"  \")\n",
    "\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "\n",
    "            pin_extract_fail.append(i)  ## update list for saving the image index which fails of voronoi generation \n",
    "\n",
    "            print(\"\\rRaw Image Data loaded \" + str(i+1), end=\"  \")\n",
    "\n",
    "            continue\n",
    "\n",
    "    \n",
    "    ####  3. Saving  ####\n",
    "\n",
    "    np.random.shuffle(data_list)  ## shuffle the graph data list\n",
    "    data_size = len(data_list)\n",
    "    train_val_size = int(data_size*0.75)  ## size of train/val dataset, 75%\n",
    "    test_size = int(data_size*0.25)  ## size of test dataset, 25%\n",
    "\n",
    "    train_val_data = data_list[:train_val_size]  ## train/val dataset\n",
    "    test_data = data_list[train_val_size+1:]  ## test dataset\n",
    "\n",
    "    train_val_data_file = train_data_dir + '/Train_val_data_list.pt'\n",
    "    torch.save(train_val_data, train_val_data_file)  # save the train_val data_list as pt file\n",
    "\n",
    "    test_data_file = test_data_dir + '/Test_data_list.pt'\n",
    "    torch.save(test_data, test_data_file)  # save the test data_list as pt file\n",
    "\n",
    "    cost_time = time.time() - start\n",
    "    print(\"\\nVoronoi Graph Dataset Loading Complete!!!\")\n",
    "    print(\"The shape of processed images = \", processed.shape)\n",
    "    print(\"The whole number of processed images = \", count)\n",
    "    print(\"The whole number of train/validation dataset = \", train_val_size)\n",
    "    print(\"The whole number of test dataset = \", test_size)\n",
    "    print(\"The fail number of pin extraction = \", len(pin_extract_fail))\n",
    "    print(\"The fail number of voronoi generation = \", len(voronoi_fail))\n",
    "    print(\"The whole time of voronoi graph construction = \", cost_time)\n",
    "    print(\"The voronoi graph construction frequency = \", count/cost_time)\n",
    "    print(\"Each voronoi graph construction time = \", cost_time/count)\n",
    "    print(\"Image preprocessing and Voronoi Graph generating successfully!\")\n",
    "\n",
    "    return train_val_data, test_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Voronoi Graph Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Image Data loaded 5000  \n",
      "Voronoi Graph Dataset Loading Complete!!!\n",
      "The shape of processed images =  (300, 300)\n",
      "The whole number of processed images =  4841\n",
      "The whole number of train/validation dataset =  3630\n",
      "The whole number of test dataset =  1210\n",
      "The fail number of pin extraction =  160\n",
      "The fail number of voronoi generation =  0\n",
      "The whole time of voronoi graph construction =  258.6172387599945\n",
      "The voronoi graph construction frequency =  18.71878310669232\n",
      "Each voronoi graph construction time =  0.05342227613302923\n",
      "Image preprocessing and Voronoi Graph generating successfully!\n"
     ]
    }
   ],
   "source": [
    "raw_data_dir = r'..\\data\\331\\model_surface2d\\frames_bw'  ## raw image dir\n",
    "train_data_dir = r'..\\result\\train'  ## train data saving dir\n",
    "test_data_dir = r'..\\result\\test'  ## test data saving dir\n",
    "\n",
    "## run the dataset generation...\n",
    "voronoi_graph_data_list = voronoi_graph_datatset_generate(raw_data_dir, train_data_dir, test_data_dir, tip_num = 331)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ea547e6875eb350accb72b1da4557ac206e2c32c4d9ba746d1b5cd9ea05e630"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
